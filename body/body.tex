\section{课题来源及研究的背景和意义}

\subsection{课题的来源}

项目来源：国家自然科学基金项目（编号：U1509216,U1866602）

\subsection{课题研究的背景和意义}

随着各种新兴产业的发展，包括各种应用领域，如医学，生物学，以及交通领域等，我们能从各种装置上收集得到大量的带有时间戳的多维数据，有效地分析这些时间序列数据能够帮助相关产业更好地将数据转换成效益。但是在这些大量的数据中，一些数据会表现出不正常的行为或者模式。事实上，这些异常点（Outliers）可能是由于噪声造成的，这时候我们要将其修复或者去除；或者它们表示着我们比较感兴趣的一些事件，如机器故障，恐怖袭击等。根据不同的目的要展开不同的分析\cite{koufakou2010fast}。

事实上，在数据分析领域，发现异常点一直都是比较受欢迎的一个研究方向，因为它能够找出数据中的不正常的行为。而且，现在在数据分析的过程，异常检测并处理已经成为一个十分必要的预处理过程\cite{ha2014robust}。比如，在机器学习领域，数据质量对模型表现的影响是非常大的，噪声数据可能会阻碍模型挖掘出需要的信息，所以在执行数据预处理过程中常常把异常检测作为比较重要的一环\cite{zhang2017time}。

异常检测（Outlier Detection）也是一个挖掘信息的过程。除了是数据噪声造成的异常外，异常数据往往还代表着不正常事件的发生。许多领域都对应用异常检测方法来挖掘特殊信息感兴趣，比如说恐怖袭击检测\cite{riffo2015automated}、欺诈发现、健康管理和故障调试与诊断\cite{allen2011anomaly}等。这些领域研究都有一个共同的特征，即需要检测到的行为是和正常行为是不同的，这和异常检测的定义相吻合。

时间序列（Time Series）数据不仅有着现如今数据高维，量大\cite{budalakoti2006anomaly}的特点，还有着时序特征。传统的一些数据异常检测方法在时间序列数据上是可以使用的，但是由于没有考虑数据的时序特征往往得到的结果并不理想。而且，时序数据常常表现出强烈的短期依赖性（Temporal Dependence）\cite{cai2018effective}，这就对时间序列异常检测有了更高的要求。虽然现在已经有很多关于时间序列异常检测的方法，但是仍然很难满足对现如今数据发展的要求。

\section{国内外在该方向的研究现状及分析}

已有的时间序列异常检测的方法可以分为不同的类别，不同的类别有着不同的优势和劣势。接下来几个章节主要来讲国内外已有的一些方法，并主要分析他们的优势和劣势所在。

\subsection{基于概率统计模型的时间序列数据异常检测}

基于统计的异常检测方法主要是通过数据的一些统计特征来进行异常检测的，比如说一个数据库中的数据是大致符合某个统计模型，那么异常数据往往对这个统计模型不适用或者出现的概率很低\cite{eskin2000anomaly,hido2011statistical}。但是，一方面这些方法不能够很好地移植到时间序列数据异常检测中；另一方面，随着数据维度的不断增多，传统的统计模型已经无法适应异常检测的要求。不过虽说如此，仍然有一些比较好的能够处理时间序列数据的统计模型。

Zhang et al.\cite{zhang2016sequential}应用了前人使用的基于对时间序列数据值变化速度约束从而进行异常检测的方法\cite{song2015screen}。但是传统的方法有一个缺陷是虽然它能够很好地检测出大幅度变化的异常，但是却很难检测出较小变化的异常。为此，作者改善了原文献中的依靠变化速度的最大最小值约束来进行异常检测，而是通过对速度的变化进行概率建模，并最大化似然来估计异常。巧妙地使用了概率模型来提高了异常检测的精度。

Guo et al.\cite{guo2010improved}通过分段聚集估计方法先对时间序列数据分段，随后在段上定义了几种统计特征值。然后定义了几种衡量分段聚集估计方法段之间距离方法，这些方法是通过前面计算的统计特征值来实现的。通过这些距离的定义可以计算段之间的差异程度，亦可以通过定义的距离来对时间序列数据进行异常检测。

其实，早先基于概率统计模型的时间序列异常检测的方法较多。但是这些模型大都已经不能够适应现在时间序列数据的要求，数据量越来越大，数据维度越来越高，逐渐就淘汰掉了这些方法。但是它们有着处理效率高，速度快的特点，作为预处理的一环也不失为一种好方法。

\subsection{基于机器学习的时间序列数据异常检测}

机器学习运用到时间序列数据管理已经有了很多方面的研究\cite{laure2018machine}，异常检测方法有很多是基于机器学习方法来实现的，根据机器学习方法分类可以分为监督学习和无监督学习，这主要是由数据是否有标签来决定的\cite{chandola2009anomaly}。

在有标签的训练数据上，就可以使用监督学习的方法。常常在异常检测方面，会将异常检测问题转换为一个二分类问题\cite{gupta2013outlier}。在数据集标签存在的情况下，传统的二分类算法都能够应用到异常检测上。如使用传统的监督学习算法，决策树、朴素贝叶斯、SVM的基于特征分来的算法来进行对时间序列数据进行异常检测的\cite{kang2005learning}，也有使用滑动窗口进行取数据段，然后通过对数据段进行提取特征，使用SVM进行分类的方法\cite{tian2007sequence,wang2006native}。还有对数据进行采样进行多次分类算法的，如这篇文献\cite{gonzalez2003anomaly}中，作者选择使用否定选择算法，而不是其他算法常用的抽样阳性（正确的）数据。通过将对正常数据和异常数据进行采样，使用分类算法，得到异常数据的特征并以此进行异常检测。

监督学习的方法在数据存在标签的时候是可以有比较不错的表现的，而且使用时间序列的子串来进行分类也有着不错的结果\cite{le2017time}。但是关于监督学习的方法大都是十年前的研究，因为有标签的数据集比较难得。尤其是在现在数据量不断增大，数据维度不断增多的情况。传统的标签方法常常是人工经验备注，但是数据量变大以后这种方法就变得不太现实。所以监督学习应用于时间序列数据的异常检测往往不多。

聚类是比较有代表性的无监督方法，传统的聚类方法实现的关键主要是距离的衡量，根据不同的时间序列数据库来挑选距离衡量方法是很重要的一个过程\cite{mori2015similarity}。距离衡量的方法确定后就是聚类方法的选择，传统的\(k\)-Means，GMM等都是可以使用的。异常检测过程主要就是判断数据点到它所属中心的距离来当作它的异常打分。但是，传统的聚类方法在时间序列上表现一般，除此还有使用基于托普利兹矩阵以及马尔科夫随机场（Toeplitz Inverse Covariance-based Clustering）来对时间序列数据自序列进行聚类的方法\cite{hallac2017toeplitz}，很好的解决了传统聚类方法丢失时序特征的问题。

无监督方法除了聚类，还有使用主成分分析（Principal Component Analysis, PCA）来对时间序列数据进行预测和异常检测的\cite{papadimitriou2005streaming}。这篇文章的思路大概是通过主成分分析最小化重构误差来获得时间序列数据的隐空间，然后增量训练，数据点可以带入到训练好的模型中计算输入和输出的距离来当作异常打分，从而实现异常检测。而且，为了强调时间序列数据的短期依赖性，增量训练模型的过程会给以往的模型添加遗忘因子减少权重。

还有一种构造模型的方法和聚类有点类似\cite{chan2005modeling}。对于时间序列数据，它会构建出一些box，这种方法类似于聚类中常使用的自底向上的层次聚类方法。不同的是这种方法只考虑时间序列数据中相邻数据的结合。在训练过程中，首先每个数据独立当作一个box，计算相邻box的距离并将最小的那两个合并，其中距离的计算用两个box之间点距离的最小值来得到。然后重复这个操作直到得到了k个box（k为需要指定的参数）。在测试过程中，如果新到来的数据在当前的box中，那么它的异常得分（anomaly）为0，否则就计算它和最近的box的距离，并和设置的阈值进行对比，如果超出阈值的话就说明这个点是一个异常点。

还有一种增量建立模型的方法是通过支持向量回归机（Support Vactor Regerssion, SVR）来实现的\cite{ma2003online}。SVR和SVM类似，只是SVR要寻找的最优超平面是使所有的样本点离着超平面的总偏差最小。作者建立了一个异常检验的模型，包括预测模型，异常区间，异常数量等等，然后将SVR代入到这个模型中。当前时刻预测下一个点的值（离超平面近的点）然后与实际的值进行对比，通过异常区间的阈值来判断该点是否异常，并将这个点加入到模型中重新构造模型。

除了这些方法外，其实还有很多无监督方法能应用于时序数据异常检测，如隐马尔科夫模型（Hidden Markov Models, HMMS）\cite{florez2005efficient}，有穷状态机（Finite state Automata, FSA）\cite{chandola2008comparative}等等。

基于距离的时间序列研究方法可行的原因是十分直观的：一个观测点如果距离离他最近的点都很远的话，那么它就很有可能是一个异常点。做法也比较直观，首先找到所有点距离它最近的点，然后以最近点的距离当作权值对所有的所有点排序，那些距离大的点就可以被当作是异常点，这是比较经典的一篇实现\cite{huang2013rank}。

所以，对这种方法而言，距离的定义就成为比较重要的一环。在定义距离的这些方法中，$k$NN是经常使用的一种方法。一种方法是以$k$NN中$k$个点的最远距离当作距离的衡量\cite{ramaswamy2000efficient}，另一种方法是以$k$NN中$k$个点的距离和当作距离的衡量\cite{angiulli2002fast}。除此，为了加速对$k$NN的查询，还有在数据集上建立最小生成树，从而加快对$k$NN的查询来实现异常检测的\cite{wang2015fast}。

基于距离的时间序列数据异常检测有很大的优点，即算法简单高效。而且，如果以时间序列数据的数据段为单位进行距离衡量的话往往能比较高效地查询到数据中存在的区间异常。但是也存在很大的缺陷，对时间序列数据的距离衡量来说，一方面，数据的维度很大，距离衡量在一方面会受某个维度的影响。而且，当数据量很大的时候，可能异常点的数量也会随之增大，造成使用$k$NN等的方法不能够很好地找到异常数据\cite{aggarwal2015outlier}。

\subsection{基于深度学习的时间序列数据异常检测}

基于深度学习的时间序列数据异常检测是近年比较热门的研究方向。尤其在卷积神经网络（Convolutional Neural Network, CNN）以及循环神经网络（Recurrent Neural Network, RNN）中表现比较突出。在时间序列上的应用大致分两个方面：一方面是通过神经网络来对时间序列数据进行预测，通过比较预测值和原始数据的距离来判断异常；另一方面是使用自编码器最小化重构误差\cite{srivastava2015unsupervised}来实现。

具体来说，有使用循环神经网络的变种长短期记忆模型（Long Short-Term Memory, LSTM）对时间序列数据进行预测并以此进行异常检测的方法\cite{filonov2016multivariate}。这种方法通过对数据进行分段，得到一个数据段序列，然后以数据段的顺序分别以相邻的两个数据段当作长短期记忆模型的输入和输出，异常检测通过计算预测值和实际值的MSE来打分实现。

也有使用多层卷积网络最小化重构误差训练模型并以此异常检测的方法\cite{kieu2018outlier}。通过多层的卷积网络，首先把原始数据降维，然后再升维，训练过程中使升维后的结果等于原始数据段，这样就能够得到包含数据信息的隐空间。异常检测过程就计算输入和输出的MSE当作异常打分。

除此，最近的工作中还有使用稀疏连接的循环神经网络（Sparsely-connected Recurrent Neural Networks, S-RNN）来生成多种自编码器，这些自编码器分为多种不同的结构，然后仍然通过最小化重构误差来训练模型，通过计算输入和输出的MSE来做当异常打分获得异常数据\cite{kieu2019outlier}。

此外，还有使用生成对抗网络来对时间序列数据进行异常检测的\cite{li2019mad}。作者通过训练生成对抗网络，形成产生器（generator）和判别器（discriminator），对抗网络内部通过LSTM-RNN实现，也在网络攻击数据上取得了不错的效果。

深度学习的方法在多维数据上表现很好，而且循环神经网络等也能很好地适应时间序列数据处理的要求，但是这些准确性都是基于复杂的神经网络和高密度的训练过程的。现如今随着数据量、数据维度的不断增大，训练神经网络让这个过程不太轻松。

\subsection{半监督学习以及基于半监督学习的异常检测}

\subsubsection{半监督学习研究进展}

机器学习领域中的半监督学习已经有了比较多的相关研究\cite{Hady2013Semi}，这里就不对一些年代久远的方法进行赘述了。主要讨论一下近期半监督学习领域的研究进展以及半监督学习在异常检测技术上的一些利用。

Kingma et al.\cite{Kingma2014Semi}将无监督的变分自编码器扩展成为了两种不同形式的半监督模型。其中的M1是一种比较简单潜在特征判别模型，在样本的潜在表示顶端，训练出一个分类器来预测标签。在对变分自编码器的训练过程中，有标签和无标签数据都被使用了，但是分类器是使用有标签的数据来训练的。另一种M2则就相对复杂一些。除了在样本潜在表示顶端使用分类器外，还由另一个由标记数据和未标记数据共同生成的类别变量有关。最后，可以通过将M1模型的嵌入表示来学习M2来将M1和M2模型进行结合。除了这篇比较有代表性以外，\cite{siddharth2017learning, sonderby2016ladder}也是对自编码器进行扩展，从而形成半监督模型。

生成对抗网络GAN也主要通过两个方面来进行半监督学习。其中一种是考虑生成K+1个分类器，其中前K个用于对给定的标签数据进行分类，然后对于未标记数据，将其带入到训练好的前K个分类器中来得到他们的分布，然后使用特征匹配技术来解放竞争性性能\cite{DBLP:journals/corr/SalimansGZCRC16}。另一种考虑将学习的GAN模型的生成器作为流形学习的参数化，可以通过流形切线来表示数据的标签\cite{DBLP:conf/cvpr/QiZHEWH18}。

此外，teacher-student模型也是近些年来半监督学习研究的主要模型之一。其思想大致是首先通过有标签数据获得一组教师，然后使对无标签数据的预测作为学生，通过教师来监督学生的学习，通过最大化教师和学生之间的一致性，来提高学生对无标签数据进行分类时的准确性和稳定性。按照不同的强化教师和学生一致性的方法，可以将模型分为不同的种类。

比如说通过在模型的输入层和隐藏层添加噪声\cite{DBLP:journals/jmlr/SrivastavaHKSS14}来提高模型的性能。这个的思想其实和在目标函数中添加正则项是类似的。在teacher-student模型中，将添加了噪声的样本输入到模型中，从而能够获得一个有噪声的teacher，然后将预测偏差最小化，在teacher和student之间训练模型。这就是teacher-student模型中的Γ模型\cite{DBLP:conf/nips/RasmusBHVR15}。或者在两个损坏的副本之间训练，这就是teacher-student模型中的Π模型\cite{DBLP:conf/iclr/LaineA17}。

除此，这些想法还扩展到了在时间上训练一群教师，让他们来临时的指导学生来学习，然后通过使用他们的指数移动平均值来提高教师对无标签数据预测的准确性\cite{DBLP:conf/iclr/LaineA17}。亦或者通过对模型的参数进行指数加权平均，形成对集成化教师的预测，这种做法也被叫做Mean Teacher\cite{DBLP:conf/iclr/TarvainenV17}。这些方法都依赖于添加到输入样本和模型参数中的随机噪声，从而加强训练过程中教师和模型预测结果之间的一致性，以及对无标签数据预测标签的稳定性。

teacher-student模型还有另外一种优化方法，不是通过添加噪声来实现的，而是产生一个对抗性老师。通过使教师于对抗化示例的偏差最小化的思想来训练和更新学生。这样就产生了新的方法——虚拟对抗训练VAT\cite{DBLP:journals/pami/MiyatoMKI19}。这也是半监督学习领域目前有state-of-the-art标签的算法。

\subsubsection{基于半监督学习的异常检测研究}

使用半监督学习来进行异常检测一直是异常检测领域比较空缺的一部分。一方面，异常检测数据按标签的分布往往是不均衡的，这就导致分类算法直接使用于异常检测领域效果不好。另一方面，由于异常数据的随机性，往往无法得到所有情况下异常数据的分布，只靠给定的少部分异常数据很容易在训练过程中过分拟合这些数据。因此业界也常常使用无监督学习来进行异常检测。但是，无监督学习对数据分布进行的假设过强，在一些数据上就可能会存在瓶颈。而且在现实中我们是可以通过专家或者经验来获得一部分数据标签的\cite{DBLP:conf/cvpr/BilenV16}。合适地使用这些少量的标签是能够学习出更多的特征，达到比无监督学习更好地效果的。下面来介绍一下使用半监督学习来进行异常检测的一些研究。

前面我们提到使用自编码器来进行异常检测的方法。我们训练的过程是直接将所有的训练数据代入到自编码器中，然后使用自编码器来进行异常检测。这里我们是将训练数据中的未知标签的正常数据和异常数据都作为输入和输出训练出的自编码器。因为数据中异常数据很少，所以我们学习到的大部分都是正常数据的特征。\cite{DBLP:conf/mlsp/MunawarVM17}认为这种做法可能会使网络学习到异常数据的特征，从而降低了学习的准确性。因此他提出了一种半监督学习方法，通过改变代价函数，强制使正常数据最小化重构误差，异常数据最大化重构误差来强化对抗网络的重构能力。但是我觉得这种方法是存在一定的问题的。因为有标签数据的稀少，这样使少量的以上数据强制最大化重构误差会使模型过分拟合这部分异常数据，泛化能力较差。

另一种半监督学习异常检测算法使用了k-means的思想。通过在所有数据上（包括标签数据和无标签数据）进行聚类，然后在每一个簇上，通过整合其中所有有标签的数据的标签来判断这个簇的特征，从而判断这个簇上是否有异常数据\cite{DBLP:conf/sac/GaoCT06}。这是一种比较简单的方法。

还有一种半监督学习异常检测方法只使用正常数据和大量的无标签数据来进行异常检测\cite{DBLP:journals/ijait/DaneshpazhouhS15}。主要是思想是，首先通过$k$NN算法，来提取出一些比较可靠的异常数据。这部分主要是通过那些有标签的正常数据和所有数据的分布来实现的。然后对于获得的数据标签，使用Fuzzy Rough Semi-Supervised Outlier Detection\cite{DBLP:journals/mcs/XueSF10}算法来检测异常数据。这部分主要是通过一个概率矩阵来实现的。这个算法在异常检测方面优于无监督学习的最新技术。

直接使用半监督学习进行异常检测在部分情况下是优于无监督学习异常检测技术的。但是由于数据集中正常数据和异常数据不均衡是难以解决的问题，导致半监督学习分类算法在异常检测领域难以有好的结果。常常在训练过程中因为异常数据标签少而导致过分拟合异常数据，此时常常只能检测出一种或者几种异常。

\subsection{基于元学习的异常检测模型}

近两年也有元学习应用到异常检测领域的。Zhao et al.\cite{DBLP:journals/corr/abs-2009-10606}就使用元学习为不同场景下的数据挑选合适的无监督学习网络模型。他们提出的METAOD包含两个过程，首先是离线的元学习训练，通过计算不同模型在随机初始化的数据集上的性能表现，训练挑选出标签最好的网络模型，而且还引用了很多AutoML中常用的特征，包含最大值、最小值、均值、方差等。在线的检测就是通过训练得到的模型实时地提供性能最好的网络模型。这个网络模型其实更像是使用元学习来做网络模型的推荐，而不是之间使用元学习来进行异常检测。

Ding et al.\cite{DBLP:conf/www/DingZT021}在图异常检测领域使用了元学习。这篇论文面向的同样也是小样本学习的场景，提出了一种新的图偏差网络（GND）。它可以利用少量的标记异常来解决小样本学习网络检测过程中遇到的异常。同时为提出的GND提出了跨网络的元学习算法，通过从多个辅助网络传输元知识来实现小样本的异常检测。这部分研究就是直接在小样本学习网络中应用到了元学习，获得了不错的检测结果。

Tomoharu et al.\cite{DBLP:journals/corr/abs-2103-00684}使用one-class分类器进行异常检测，这种分类器既可以只使用正常数据来进行异常检测，也可以运用异常样本来提高算法的准确性。然后通过元学习的思路和特征提取的思路训练并迁移网络模型，最后训练得到最终的版本。这个研究跟我进行的度量学习有点像，也是将数据映射到嵌入空间后使用one-class分类器来进行异常检测，检测数据是否为正常样本，否则就为异常。

目前来说，元学习在时间序列异常检测方面的研究还是比较少，但是元学习的小样本学习能力可以适用到异常检测来，这也是我毕设想做的一部分内容之一。

\subsection{国内外文献综述的简析}

现在相对而言，时间序列异常检测已经有了许多可行的解决方案，分为不同的方面。这些研究成果在许多领域都有了应用而且产生了不错的效益。基于概率统计的模型在之前集群算力不够的时候是常用的方法，而且早先的数据并不像现在这样数据量大、数据维度高。但是现如今的数据呈现量大、维度高、关联性强等特点，一些简单的概率统计模型已经无法适应现在的要求。所以一些深度学习方法逐渐地也被应用到异常检测来。整体来讲，现在业界还存在一下几个问题：

\begin{itemize}
    \item 数据量和数据维度不断地增大，传统的机器学习等方法在适应高维度和大量数据上显得越来越吃力，处理需要的时间已经逐渐增加到无法接受的地步；
    \item 传统的异常检测算法不能达到时间序列异常检测的要求。因为时序特征是时间序列的重要特征，其明显特征就是短期依赖较强，如何合理的提取时间序列中的时序特征是亟待解决的问题；
    \item 真实场景下的标签数据难以获取，而一些领域的先验知识无法得到运用，所以如何融合大量的无标签数据和知识是一个很重要的问题；
    \item 小样本场景下的异常检测目前的研究较少。
\end{itemize}

我的毕设研究主要就是基于这几个问题来进行。

\section{主要研究内容}

我的毕业设计的研究内容主要从数据标签的获取难易程度入手，主要分为以下几点：

\begin{itemize}
    \item 无监督学习时间序列异常检测算法：无需数据标签就可以使用的异常检测算法，通常通过计算数据的离群程度来判断数据是否为异常点；
    \item 半监督学习时间序列异常检测算法：可以利用起有限标签的异常检测算法，因为真实的场景是我们常常可以获取到一部分先验知识，这些先验知识可以转换为部分数据的标签，利用起这部分标签能更有效地进行异常检测；
    \item 小样本学习时间序列异常检测算法：和半监督不同，这里着重研究的元学习、迁移学习等在时间序列异常检测领域的使用，在时间序列的场景下，如何利用已有的模型、知识，通过少量数据微调来获得更好的性能。
\end{itemize}

\subsection{不使用数据标签：无监督学习时间序列异常检测算法}

具有无监督学习算法是异常检测算法中使用频率最高的，现在很多研究和基准的异常检测算法都是基于无监督学习的。因为无监督学习模型在使用的时候不需要标注的数据，用起来简单，更适用于大多数场景，所以现在多数异常检测的研究方向都是在无监督学习上的。

自编码器是一种常见的神经网络模型，它可以用来做数据压缩、数据编码等，而且它天然的提取低维特征——重构原数据的模式使其能够用于异常检测领域。目前自编码器在异常检测领域已经有了一些研究，但是在时间序列的异常检测方面研究还是相对较少，而且现有的时间序列异常检测模型都相对简单，如PAA-AE，LSTM-AE和CNN-AE等。所以我考虑从这个方面入手，设计并实验验证得到一个真正适用于时间序列的异常检测自编码器模型。

考虑到现有的网络模型对时间序列的特征提取都不够：单独的RNN对时序数据的特征提取已经无法满足高维数据的要求，而非循环的神经网络又无法获得时序数据中的长期依赖，所以在未来的研究中，我想能够融合一些现在表现比较好的特征提取模型，包含时序特征的抽取和高维数据的抽取等。然后再根据这个模型构建一个自编码器用于异常检测，同时在实验验证中不断验证模型是否有更好的结果。

\subsection{使用部分标签：基于度量学习的时间序列异常检测算法}

无监督学习因为其适用性广、门槛低等优点被广泛应用，但是它的对应的归纳偏置却限制了它准确性：无监督学习异常检测算法是假定数据分布密集的部分是正常数据分布的范围，而离群点大多分布在偏离数据分布密集的位置。这种归纳偏置符合我们的直观认知，但是在一些场景下，它却也是不合理的。如风电机产生的数据中，异常包括Sparse Outliers和Stacked Outliers，其中的Stacked outliers就是聚集分布的异常点，使用传统的无监督异常检测方法会将这些数据误判为正常点。但是其实此时我们是知道这部分点的异常情况的，无监督学习方法无法利用这些知识帮助检测异常。

所以，如果能够利用起少量的数据标签用于辅助异常点的决策，如在前面的例子中，能否利用起已知的Stacked Outliers先验，告诉模型这部分堆积的数据也是异常数据呢？我们知道，监督学习是能够利用起数据中的标签的，但是，监督学习面向的是标签的数据，我们现在仅有部分标签和先验知识，如果只在这些数据上使用监督学习的话，又会使模型过拟合于这部分数据。所以，我们需要既利用起有限的标签和知识，也要利用起大量的无标签数据来辅助对异常点的判断，这其实就是半监督学习的思路。

想到半监督学习的异常检测，我们很容易就能想到使用半监督的分类模型来解决，将正常和异常的样本视为两类，转换为一个二分类问题。但是实际上，异常检测问题并不能简单地被归纳为二分类问题，因为通常情况下异常数据的特征是不可控的，即我们无法通过一种统一的模式来识别所有的异常。通常在异常检测领域的做法是，转换为单分类问题（one-class classification）。

基于这一点入手，我未来会从度量学习入手。原来的度量学习是针对分类问题，将数据映射到一个理想的嵌入空间上。嵌入的规则就是使相同类比的数据进行成簇分布。在异常检测方面，和分类问题会有很大的不同。暂定的想法是，使所有的正常样本在嵌入空间中尽量地聚簇分布，而使异常样本距离正常样本的距离尽量地远，通过神经网络将数据映射到这样的一个嵌入空间中，从而根据嵌入的数据到正常簇的距离，判断数据是否异常。这个过程需要适合的网络模型设计和损失函数的设计。同时，为了利用起无标签的数据，可以利用度量学习模型对现有的数据集进行扩容，为无标签的数据打上不同置信度的标签，不断地迭代优化模型。

而且，基于度量学习的时间序列异常检测算法还可以引申到在线学习的检测。因为某些适合会需要实时的时间序列异常检测，所以在线算法也是有很大的应用空间的。这些都会在未来的研究中体现。

\subsection{小样本学习：基于元学习的时间序列异常检测算法}

仅有少量样本的场景下，小样本学习（few-shot learning）是一个很好的选择。其实从某种程度来说，前面的半监督学习方法也可以归为小样本学习的一种。但这部分和半监督学习不同，这里使用少量样本的方式是元学习、迁移学习这些。这些方法在图像、音视频领域都有了很多研究，但是在时间序列领域还是鲜有研究。而现在工业数据越来越多，小样本的场景也越来越多，如何将这些方法应用到时间序列的异常检测领也是十分重要的。

元学习的目标是在多个任务的训练中，在新的任务执行前，能够根据任务的数据，找到一个最适合该任务的参数初始化方式，然后再根据数据的少量标签对模型进行微调，使模型能够迅速地收敛到新的模型和数据上。因为基于元学习的时间序列异常检测模型很少，所以未来首先要进行调研，找一些合适的任务集合和网络模型（或者使用前面的半监督学习模型），从而能够使模型在只有少量数据的新任务上，也能产生好的结果。

\section{已完成的研究工作}

\begin{itemize}
    \item[(1)] 无监督学习异常检测方面，现在已经有了成型了思路，也做了一些实验验证，模型是有效果的；
    \item[(2)] 度量学习方面，目前已经完成了调研，也有了基本的思路。基础特征提取模型也已经形成，架构上还需要根据实验结果进一步做调整；
    \item[(3)] 元学习方面，现在还处于调研和思考的阶段，方向已经确定，但是如何实现、实现到什么程度还是要在未来进行调整；
    \item[(4)] 实验框架设计也已经有了成型的思路，现在的研究内容是有递进关系的，实验过程也会对不同的方法进行对比。同时也找了一些合适的时间序列异常检测数据集，包含低维、高维、公开、工业界各个方面。
\end{itemize}

\section{研究方案及进度安排，预期达到的目标和取得的研究成果}

\subsection{研究方案}

\begin{itemize}
    \item[(1)] 完成无监督学习已有的想法，进一步进行实验，优化融合模型的自编码器上。整理总结相关的文档，形成完整的模型；
    \item[(2)] 进一步调研学习度量学习，基于不同的网络模型，测试提出的度量学习异常检测损失函数，调整权重完善模型。同时在不同的数据集上进行实验并可视化，验证算法的有效性。
    \item[(3)] 扩展半监督学习异常检测模型，提出有效的数据标签扩充方案，并设置伪标签的置信度计算策略，挑选置信度高的伪标签数据进一步优化模型；
    \item[(4)] 将基于度量学习的半监督异常检测算法扩展到在线学习，提出增量学习模型的学习策略，包含数据扩充策略以及参数增量更新策略等；
    \item[(5)] 调研元学习在时间序列的应用，设计网络和损失函数，使用合适的模型在异常检测数据集上进行实验测试，在小样本的情况下向新场景扩展，确保模型的稳定性和性能；
    \item[(6)] 在业界公开和工业界电网数据集上进行测试实验，计算模型进行异常检测的准确率、召回率、AUC等值，和已有的baseline和最新的算法进行比较，同时验证模型在不同的场景下是否有预期的收敛行为，观察自编码器的重构效果、度量学习的嵌入空间分布等； 
    \item[(7)] 形成一个统一的架构，根据知识和标签的拥有比例，为使用者提供合适的异常检测算法。
\end{itemize}

\subsection{进度安排、预期达到的目标}

进度安排如表\ref{table}

\begin{table}[]
    \caption{进度安排}
    \label{table}
    \resizebox*{\textwidth}{44mm}{
    \begin{tabular}{@{}cc@{}}
        \toprule
    起止时间          & 进度安排                            \\ \midrule
    现在——11月中旬     & 阅读论文，进一步完善想法，完成无监督学习异常检测模型，测试指标 \\
    11月中旬——秋季学期结束 & 确定度量学习的思路，代码实现度量学习异常检测模块        \\
    秋季学习结束——中期答辩  & 实验验证并调整度量学习异常检测模块，形成最终版本，测试指标   \\
    中期答辩——四月中旬    & 补充元学习相关的知识，整理出可行的异常检测思路         \\
    四月中旬——五月中旬    & 代码实现元学习相关的内容，测试指标，总结文档          \\
    五月中旬——结题答辩    & 统一整理三方面研究的内容，形成一个整体的异常检测系统        \\ \bottomrule
    \end{tabular}}
\end{table}

\section{为完成课题已具备和所需的条件和经费}

\begin{itemize}
    \item[(1)] 知识储备方面，现在已经阅读了一系列的文献，对无监督学习、半监督学习算法有了一定的了解，而且无监督学习已经实现了一些算法，后期只需要调试和验证即可；
    \item[(2)] 硬件方面，能够使用海量数据研究中心的集群；
    \item[(3)] 数据方面，目前有和国家电网合作的工业数据集，同时也准备了yahoo、UCR等时间序列公开数据集供未来实验使用；
    \item[(4)] 软件方面，torch框架现在已经熟悉，而且实现了一些自编码器模型；
    \item[(5)] 经费方面，研究过程中能使用到经费的地方不多，大多是一些文献的下载、书籍的购买等，以及一些计算资源的使用。
\end{itemize}

\section{预计研究过程中可能遇到的困难和问题，以及解决的措施}

\begin{itemize}
    \item[(1)] 网络模型的挑选和参数的选择，这部分经验较为欠缺，如何最好的发挥模型的作用需要针对不同的场景进行参数调整，这一点需要不断试验；
    \item[(2)] 标签数据较难获得，这部分不是要标签数据来在检测适合使用，而是验证的过程中使用。因为公开的标签异常检测数据集较少，所以可能会需要找一些二分类数据集；
    \item[(3)] 元学习现在的了解程度还不够，还需要进一步的阅读相关的论文和文档，如何划分数据集，如何训练、迁移，都是需要学习的地方；
    \item[(4)] 半监督学习过程中因为数据扩充是根据已有的标签数据，所以很可能会过拟合这部分数据，如何根据无标签数据的分布解决过拟合问题也是比较困难的研究点；
\end{itemize}

\bibliographystyle{hithesis}

\bibliography{reference}